#! /usr/bin/env python3
# _*_ coding:utf-8 _*_
import requests
from bs4 import BeautifulSoup
from urllib.parse import urlparse
import sys

#'Accept-Language': "zh-CN,zh;q=0.8,zh-TW;q=0.7,zh-HK;q=0.5,en-US;q=0.3,en;q=0.2",
headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:83.0) Gecko/20100101 Firefox/83.0',
           'Accept': '*/*',
           'Accept-Language': 'en-US,en;q=0.5',
           'Accept-Encoding': 'gzip, deflate',
           'referer': "http://cn.bing.com/search?q=email+site%3abaidu.com&qs=n&sp=-1&pq=emailsite%3abaidu.com&first=2&FORM=PERE1"
           }

def bing_search(site, pages):
    Subdomain = []

    for i in range(int(pages)):
        url = "https://cn.bing.com/search?q=site%3a" + site + "&first=" + str(i*10)
        conn = requests.session()
        conn.get('http://cn.bing.com', headers=headers)
        html = conn.get(url, stream=True, headers=headers, timeout=8)
        soup = BeautifulSoup(html.content, 'html.parser')
        with open('a.html', 'w', encoding='utf-8') as jobj:
            jobj.write(soup.text)

        data_baidus = soup.findAll('h2')
        print(data_baidus)
        for data_baidu in data_baidus:
            link = data_baidu.a.get('href')
            domain = urlparse(link).netloc
            if domain in Subdomain:
                pass
            else:
                Subdomain.append(domain)

bing_search('www.baidu.com', 5)
